{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##    Trabajo práctico Nro 1\n",
        "\n",
        "## **Procesamiento de Lenguaje Natural**\n",
        "\n",
        "## Integrantes:\n",
        "\n",
        "*   Kidonakis, Sol\n",
        "*   Leguiza, Claudia E\n",
        "\n",
        "\n",
        "\n",
        "###                  Año: 2024"
      ],
      "metadata": {
        "id": "d9bOJzyeh1AZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import csv\n",
        "import pandas as pd\n",
        "import lxml\n"
      ],
      "metadata": {
        "id": "eap0qH0lnX6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc99ULwfhuzq"
      },
      "outputs": [],
      "source": [
        "# Dirección de la página web\n",
        "url = \"https://ww3.lectulandia.com/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar GET-Request\n",
        "response = requests.get(url)"
      ],
      "metadata": {
        "id": "3fBXlC2vnDbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "pSYISyzCnv3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cargamos el texto y localizamos los datos que necesitamos para armar el archivo CSV"
      ],
      "metadata": {
        "id": "bKYRgcXn-Cmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html = BeautifulSoup(response.text, 'html.parser')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "f23L15DWnJxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "genero_html = html.find_all(\"a\", class_ = \"term\")\n",
        "genero_html"
      ],
      "metadata": {
        "id": "vmpI0K0kyJMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resumen_html = html.find_all('div', class_=\"description\")\n",
        "resumen_html"
      ],
      "metadata": {
        "collapsed": true,
        "id": "i1fghmGxr8QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "titulo_html = html.find_all('a', class_=\"title\")\n",
        "titulo_html"
      ],
      "metadata": {
        "id": "efFz1Ub2sT69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "autor_html = html.find_all('div', class_=\"subdetail\")\n",
        "autor_html"
      ],
      "metadata": {
        "collapsed": true,
        "id": "0EAg3RyFtB4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definimos los 10 generos que vamos a cargar"
      ],
      "metadata": {
        "id": "0sgvYJpgKnQi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Scraping"
      ],
      "metadata": {
        "id": "SH96xEIuBG4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza el parseo del contenido deseado según las etiquetas html del sitio."
      ],
      "metadata": {
        "id": "i1L1p6LOBSyy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "stop_words = list(stop_words)\n",
        "\n",
        "\n",
        "def scrape_lectulandia():\n",
        "\n",
        "    base_url = \"https://ww3.lectulandia.com/genero/\"\n",
        "    generos = ['cuentos', 'humor', 'infantil', 'medicina', 'musica','poesia',\\\n",
        "               'politica', 'sociologia','tecnologia', 'viajes']\n",
        "    libros = []\n",
        "\n",
        "    for genero in generos:\n",
        "            url = f\"{base_url}{genero}\"\n",
        "            response = requests.get(url)\n",
        "            if response.status_code != 200:\n",
        "                break  # Rompe el bucle si la página no existe\n",
        "            soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "            # Extraer los elementos de los libros\n",
        "\n",
        "            titulos = soup.find_all('a', class_='title')\n",
        "            autores = soup.find_all('div', class_='subdetail')\n",
        "            resumenes = soup.find_all('div', class_='description')\n",
        "\n",
        "            for titulo, autor, resumen in zip(titulos, autores, resumenes):\n",
        "\n",
        "                libro_titulo = titulo.get_text(strip=True)\n",
        "                libro_autor = autor.get_text(strip=True)\n",
        "                libro_genero = genero  # Usamos el género que estamos iterando\n",
        "                libro_resumen = resumen.get_text(strip=True)\n",
        "\n",
        "                libros.append({\n",
        "                    'titulo': libro_titulo,\n",
        "                    'autor': libro_autor,\n",
        "                    'genero': libro_genero,\n",
        "                    'sinopsis': libro_resumen\n",
        "                })\n",
        "\n",
        "    return libros\n"
      ],
      "metadata": {
        "id": "2AWawFVjXg_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "libros = scrape_lectulandia()\n",
        "df = pd.DataFrame(libros)"
      ],
      "metadata": {
        "id": "gVYihJb2KvgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos la carga correcta de los generos seleccionados y el balanceo del dataset."
      ],
      "metadata": {
        "id": "smv9aipTL1iI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['genero'].unique()"
      ],
      "metadata": {
        "id": "qFnxwgr9KyVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['genero'].value_counts()"
      ],
      "metadata": {
        "id": "REtRbUlNKz6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ugCQaXJtb3Ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El dataset **df** se guarda un archivo **libros_lectulandia.csv**"
      ],
      "metadata": {
        "id": "djQ_OsJcLvo5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('libros_lectulandia.csv', index=False)"
      ],
      "metadata": {
        "id": "c6F_5ko8K1mG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Carga del archivo**"
      ],
      "metadata": {
        "id": "vHRS1lUfLjiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "libros = pd.read_csv('libros_lectulandia.csv')\n",
        "libros.sample(10)"
      ],
      "metadata": {
        "id": "pJaRQR3lK4TC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "08jS4juBXVcG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "libros['sinopsis'][101]\n"
      ],
      "metadata": {
        "id": "N4UYz65mK6yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Eliminacion de acentos,puntuaciones,mayusculas y espacios en blanco**"
      ],
      "metadata": {
        "id": "hBRt3FKBcGiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import unicodedata\n",
        "\n",
        "def preprocesar_texto(texto):\n",
        "    # Convertir a minúsculas\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # Eliminar acentos\n",
        "    texto = ''.join(c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "    # Eliminar puntuación\n",
        "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
        "\n",
        "    # Eliminar espacios en blanco adicionales\n",
        "    texto = re.sub(r'\\s+', ' ', texto).strip()\n",
        "\n",
        "    return texto\n"
      ],
      "metadata": {
        "id": "ZaeAHBJEcVSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recomendacion directa**"
      ],
      "metadata": {
        "id": "RGQMjNJLfnD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "RPCmkE9zPMwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Función para tokenizar las sinopsis\n",
        "def tokenizar_sinopsis(sinopsis):\n",
        "    return word_tokenize(sinopsis.lower())\n",
        "\n",
        "# Tokenizar las sinopsis y entrenar el modelo Word2Vec\n",
        "textos_tokenizados = [tokenizar_sinopsis(sinopsis) for sinopsis in df['sinopsis']]\n",
        "modelo_word2vec = Word2Vec(sentences=textos_tokenizados, vector_size=100, window=5, min_count=1, workers=4)"
      ],
      "metadata": {
        "id": "wrxOqSwOUpV0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recomendacion_directa_word2vec(entrada_usuario, df, modelo_word2vec, num_recomendaciones=3):\n",
        "    # Preprocesar la entrada del usuario\n",
        "    entrada_procesada = preprocesar_texto(entrada_usuario)\n",
        "\n",
        "    # Calcular la similitud entre la entrada del usuario y las sinopsis de los libros usando Word2Vec\n",
        "    similitudes = {}\n",
        "    for idx, row in df.iterrows():\n",
        "        similitudes[idx] = modelo_word2vec.wv.n_similarity(entrada_procesada.split(), row['sinopsis'].split())\n",
        "\n",
        "    # Ordenar por similitud descendente\n",
        "    similitudes_ordenadas = sorted(similitudes.items(), key=lambda x: x[1], reverse=True)\n",
        "    libros_relevantes = df.iloc[[idx for idx, _ in similitudes_ordenadas[:num_recomendaciones]]]\n",
        "\n",
        "    return libros_relevantes\n"
      ],
      "metadata": {
        "id": "_m-3UZWVPC5E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recomendacion por autor**"
      ],
      "metadata": {
        "id": "BTbU7qdlg-h4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import random"
      ],
      "metadata": {
        "id": "SXywpHinhHzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para recomendar libros por autor\n",
        "def recomendar_libros_por_autor(autor):\n",
        "    # Preprocesar el nombre del autor\n",
        "    autor_procesado = preprocesar_texto(autor)\n",
        "\n",
        "    # Calcular la similitud coseno entre el nombre del autor y todos los autores en el DataFrame\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    autor_vector = tfidf_vectorizer.fit_transform([autor_procesado])\n",
        "    autores_vectorizados = tfidf_vectorizer.transform(df['autor'])\n",
        "    similitudes = cosine_similarity(autor_vector, autores_vectorizados)\n",
        "\n",
        "    # Obtener los índices de los dos autores más similares\n",
        "    indices_autores_similares = similitudes.argsort(axis=1)[0][-2:]\n",
        "\n",
        "    # Obtener los libros asociados a los dos autores más similares\n",
        "    libros_relevantes = df[df.index.isin(indices_autores_similares)].copy()\n",
        "\n",
        "    # Seleccionar los dos libros más relevantes del autor más similar\n",
        "    libros_autor_mas_similar = libros_relevantes.iloc[0:2]\n",
        "\n",
        "    # Seleccionar uno de los libros del segundo autor más cercano al azar si hay varios\n",
        "    libros_segundo_autor = libros_relevantes.iloc[2:]\n",
        "    if len(libros_segundo_autor) > 0:\n",
        "        libro_elegido = libros_segundo_autor.sample(1)\n",
        "        libros_recomendados = pd.concat([libros_autor_mas_similar, libro_elegido])\n",
        "    else:\n",
        "        libros_recomendados = libros_autor_mas_similar\n",
        "\n",
        "    return libros_recomendados\n",
        "\n"
      ],
      "metadata": {
        "id": "PaDZuHrng-BG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Recomendacion por Genero Literario**"
      ],
      "metadata": {
        "id": "Vr5Nhk_-kVRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Función para recomendar libros por género literario\n",
        "def recomendar_libros_por_genero(genero):\n",
        "    # Preprocesar el género literario\n",
        "    genero_procesado = preprocesar_texto(genero)\n",
        "\n",
        "    # Calcular la similitud coseno entre el género literario y todos los géneros en el DataFrame\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "    genero_vector = tfidf_vectorizer.fit_transform([genero_procesado])\n",
        "    generos_vectorizados = tfidf_vectorizer.transform(df['genero'])\n",
        "    similitudes = cosine_similarity(genero_vector, generos_vectorizados)\n",
        "\n",
        "    # Obtener los índices de los géneros más similares\n",
        "    indices_generos_similares = similitudes.argsort(axis=1)[0][-2:]\n",
        "\n",
        "    # Obtener los libros asociados a los géneros más similares\n",
        "    libros_relevantes = df[df.index.isin(indices_generos_similares)].copy()\n",
        "\n",
        "    return libros_relevantes\n"
      ],
      "metadata": {
        "id": "oHdf5O7ykazR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Intraccion con el usuario**"
      ],
      "metadata": {
        "id": "F6yU7WQnmFUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mostrar recomendaciones\n",
        "def mostrar_recomendaciones(recomendaciones):\n",
        "    for idx, libro in enumerate(recomendaciones.iterrows(), start=1):\n",
        "        print(f\"{idx}. Título: {libro[1]['titulo']}\")\n",
        "        print(f\"   Autor: {libro[1]['autor']}\")\n",
        "        print(f\"   Género: {libro[1]['genero']}\")\n",
        "        print(f\"   Sinopsis: {libro[1]['sinopsis']}\\n\")"
      ],
      "metadata": {
        "id": "vVeG41GORJo_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interactuar_con_usuario(df,modelo_word2vec):\n",
        "    print(\"¡Bienvenido al recomendador de libros de Lectulandia!\")\n",
        "    print(\"¿Qué tienes ganas de leer hoy?\")\n",
        "    print(\"1. Recomendación Directa\")\n",
        "    print(\"2. Elección por Genero Literario\")\n",
        "    print(\"3. Elección por Autor\")\n",
        "    opcion = input(\"Seleccione una opción (1/2/3): \")\n",
        "\n",
        "    if opcion == \"1\":\n",
        "        entrada_usuario = input(\"Ingrese una temática o palabras clave: \")\n",
        "        recomendaciones = recomendacion_directa_word2vec(entrada_usuario,df,modelo_word2vec)\n",
        "    elif opcion == \"2\":\n",
        "        genero_usuario = input(\"Ingrese el género literario: \")\n",
        "        recomendaciones = recomendar_libros_por_genero(genero_usuario)\n",
        "    elif opcion == \"3\":\n",
        "        autor_usuario = input(\"Ingrese el autor: \")\n",
        "        recomendaciones = recomendar_libros_por_autor(autor_usuario)\n",
        "    else:\n",
        "        print(\"Opción no válida. Por favor, seleccione una opción válida (1/2/3).\")\n",
        "        return\n",
        "\n",
        "    if recomendaciones.empty:\n",
        "        print(\"Lo siento, no se encontraron recomendaciones para tu búsqueda.\")\n",
        "    else:\n",
        "        print(\"\\nAquí tienes algunas recomendaciones para ti:\\n\")\n",
        "        mostrar_recomendaciones(recomendaciones)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fLZsmZeZbAwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Ejecutar la interacción con el usuario\n",
        "interactuar_con_usuario(df, modelo_word2vec)"
      ],
      "metadata": {
        "id": "Q-n5dGZvhlIP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}